{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3bc3db6-ad16-443c-930f-4799d98df71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (10127, 27)\n",
      "      PcrKey  eDispatch_01  eDispatch_02  eResponse_05  eResponse_07  \\\n",
      "0     761495       2301061       2302001       2205001       2207023   \n",
      "1   22298602       2301003       2302007       2205001       2207015   \n",
      "2   61958750       2301061       2302001       2205001       2207017   \n",
      "3  108615464       2301061       2302001       2205001       2207015   \n",
      "4  113783964       2301071       2302003       2205007       2207017   \n",
      "\n",
      "   eResponse_23  eScene_01  eScene_06  eScene_07  eScene_08  ...  \\\n",
      "0       2223001    9923003    2707005    9923001    7701003  ...   \n",
      "1       2223001    9923003    2707005    9923001    7701001  ...   \n",
      "2       2223001    9923003    2707005    9923001    7701001  ...   \n",
      "3       2223001    9923003    2707003    7701003    7701003  ...   \n",
      "4       2223005    9923003    2707005    7701003    7701003  ...   \n",
      "\n",
      "  eSituation_20 eOutcome_01  eOutcome_02           eOutcome_11  \\\n",
      "0    Unknown        7701003      7701003  Not Applicable         \n",
      "1    Unknown        7701003      7701003  Not Applicable         \n",
      "2    Unknown        7701003      7701003  Not Applicable         \n",
      "3    Unknown        7701003      7701003  Not Applicable         \n",
      "4    Unknown        7701003      7701003  Not Applicable         \n",
      "\n",
      "            eOutcome_16           eOutcome_18 ePatient_15 ePatient_16  \\\n",
      "0  Not Applicable        Not Applicable           7701003     7701003   \n",
      "1  Not Applicable        Not Applicable                37     2516009   \n",
      "2  Not Applicable        Not Applicable                78     2516009   \n",
      "3  Not Applicable        Not Applicable           7701003     7701003   \n",
      "4  Not Applicable        Not Applicable                91     2516009   \n",
      "\n",
      "   eResponse_08  eResponse_12  \n",
      "0           NaN           NaN  \n",
      "1           NaN     2212015.0  \n",
      "2           NaN     2212015.0  \n",
      "3           NaN           NaN  \n",
      "4           NaN     2212015.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Columns after rename:\n",
      "['incident_id', 'dispatch_center_id', 'dispatch_call_id', 'service_requested_type', 'unit_transport_capability', 'response_misc_field', 'first_unit_on_scene_flag', 'num_patients_at_scene', 'mass_casualty_flag', 'scene_factor_1', 'primary_symptom_or_scene_descr', 'chief_complaint_location', 'possible_injury_flag', 'primary_impression', 'secondary_impression', 'trauma_score_or_severity', 'provider_narrative_1', 'provider_narrative_2', 'hospital_destination_code', 'ed_disposition', 'hospital_admit_time', 'hospital_discharge_time', 'long_term_outcome', 'patient_age_value', 'patient_age_units', 'crew_size_or_delay_type', 'response_additional_mode']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Load data\n",
    "# ---------------------------------------------------------\n",
    "df_raw = pd.read_csv(\"nemsis_sprint0_3_sample.csv\")\n",
    "\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "print(df_raw.head())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Rename columns\n",
    "# ---------------------------------------------------------\n",
    "rename_map = {\n",
    "    \"PcrKey\": \"incident_id\",\n",
    "    \"eDispatch_01\": \"dispatch_center_id\",\n",
    "    \"eDispatch_02\": \"dispatch_call_id\",\n",
    "    \"eResponse_05\": \"service_requested_type\",\n",
    "    \"eResponse_07\": \"unit_transport_capability\",\n",
    "    \"eResponse_23\": \"response_misc_field\",\n",
    "    \"eScene_01\": \"first_unit_on_scene_flag\",\n",
    "    \"eScene_06\": \"num_patients_at_scene\",\n",
    "    \"eScene_07\": \"mass_casualty_flag\",\n",
    "    \"eScene_08\": \"scene_factor_1\",\n",
    "    \"eScene_09\": \"primary_symptom_or_scene_descr\",\n",
    "    \"eSituation_01\": \"chief_complaint_location\",\n",
    "    \"eSituation_02\": \"possible_injury_flag\",\n",
    "    \"eSituation_07\": \"primary_impression\",\n",
    "    \"eSituation_08\": \"secondary_impression\",\n",
    "    \"eSituation_13\": \"trauma_score_or_severity\",\n",
    "    \"eSituation_18\": \"provider_narrative_1\",\n",
    "    \"eSituation_20\": \"provider_narrative_2\",\n",
    "    \"eOutcome_01\": \"hospital_destination_code\",\n",
    "    \"eOutcome_02\": \"ed_disposition\",\n",
    "    \"eOutcome_11\": \"hospital_admit_time\",\n",
    "    \"eOutcome_16\": \"hospital_discharge_time\",\n",
    "    \"eOutcome_18\": \"long_term_outcome\",\n",
    "    \"ePatient_15\": \"patient_age_value\",\n",
    "    \"ePatient_16\": \"patient_age_units\",\n",
    "    \"eResponse_08\": \"crew_size_or_delay_type\",\n",
    "    \"eResponse_12\": \"response_additional_mode\",\n",
    "}\n",
    "df = df_raw.rename(columns=rename_map)\n",
    "\n",
    "print(\"\\nColumns after rename:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbb331a-d5aa-4dd1-924b-57c415e5e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse success rate: 0.012836970474967908\n",
      "     hospital_admit_time hospital_admit_time_parsed\n",
      "0   Not Applicable                              NaT\n",
      "1   Not Applicable                              NaT\n",
      "2   Not Applicable                              NaT\n",
      "3   Not Applicable                              NaT\n",
      "4   Not Applicable                              NaT\n",
      "5   Not Applicable                              NaT\n",
      "6   Not Applicable                              NaT\n",
      "7   Not Applicable                              NaT\n",
      "8   Not Applicable                              NaT\n",
      "9   Not Applicable                              NaT\n",
      "10  Not Applicable                              NaT\n",
      "11  Not Applicable                              NaT\n",
      "12  Not Applicable                              NaT\n",
      "13  Not Applicable                              NaT\n",
      "14  Not Applicable                              NaT\n",
      "15  Not Applicable                              NaT\n",
      "16  Not Applicable                              NaT\n",
      "17  Not Applicable                              NaT\n",
      "18  Not Applicable                              NaT\n",
      "19  Not Applicable                              NaT\n",
      "20  Not Applicable                              NaT\n",
      "21  Not Applicable                              NaT\n",
      "22  Not Applicable                              NaT\n",
      "23  Not Recorded                                NaT\n",
      "24  Not Applicable                              NaT\n",
      "25  Not Applicable                              NaT\n",
      "26  Not Recorded                                NaT\n",
      "27  Not Recorded                                NaT\n",
      "28  Not Recorded                                NaT\n",
      "29  Not Recorded                                NaT\n",
      "\n",
      "Shape after dropping missing admit_time: (130, 28)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. Parse hospital_admit_time into datetime\n",
    "#    (keep only real timestamps, drop Not Applicable/Recorded)\n",
    "# ---------------------------------------------------------\n",
    "raw = df[\"hospital_admit_time\"].astype(str)\n",
    "\n",
    "# strings that are clearly not datetimes\n",
    "bad_vals = [\"Not Applicable      \", \"Not Recorded        \",\n",
    "            \"Not Applicable\", \"Not Recorded\", \"\"]\n",
    "bad_mask = raw.isin(bad_vals)\n",
    "\n",
    "# candidate datetime strings\n",
    "clean = raw[~bad_mask].str.strip()          # e.g. \"01JAN2024:06:51:00\"\n",
    "# convert \"01JAN2024:06:51:00\" -> \"01JAN2024 06:51:00\"\n",
    "clean = clean.str.replace(\":\", \" \", n=1, regex=False)\n",
    "\n",
    "parsed = pd.to_datetime(clean, format=\"%d%b%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "# attach back\n",
    "df[\"hospital_admit_time_parsed\"] = pd.NaT\n",
    "df.loc[~bad_mask, \"hospital_admit_time_parsed\"] = parsed\n",
    "\n",
    "print(\"\\nParse success rate:\",\n",
    "      df[\"hospital_admit_time_parsed\"].notna().mean())\n",
    "print(df[[\"hospital_admit_time\", \"hospital_admit_time_parsed\"]]\n",
    "      .head(30))\n",
    "\n",
    "# keep only rows with a valid timestamp\n",
    "df = df[df[\"hospital_admit_time_parsed\"].notna()].copy()\n",
    "df = df.sort_values(\"hospital_admit_time_parsed\")\n",
    "\n",
    "print(\"\\nShape after dropping missing admit_time:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b2c7e1a-97c4-414a-8299-e256fb0d6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time feature example:\n",
      "     hospital_admit_time_parsed         shift_start  admit_hour  admit_dow  \\\n",
      "2482        2023-12-31 21:02:00 2023-12-31 21:00:00          21          6   \n",
      "2819        2023-12-31 21:37:00 2023-12-31 21:00:00          21          6   \n",
      "2201        2024-01-01 00:48:00 2024-01-01 00:00:00           0          0   \n",
      "2651        2024-01-01 01:26:00 2024-01-01 01:00:00           1          0   \n",
      "2240        2024-01-01 02:21:00 2024-01-01 02:00:00           2          0   \n",
      "\n",
      "      admit_month  \n",
      "2482           12  \n",
      "2819           12  \n",
      "2201            1  \n",
      "2651            1  \n",
      "2240            1  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. Time‑based features (from parsed admit time)\n",
    "# ---------------------------------------------------------\n",
    "dt = df[\"hospital_admit_time_parsed\"]\n",
    "\n",
    "df[\"admit_year\"] = dt.dt.year\n",
    "df[\"admit_month\"] = dt.dt.month\n",
    "df[\"admit_day\"] = dt.dt.day\n",
    "df[\"admit_hour\"] = dt.dt.hour\n",
    "df[\"admit_dow\"] = dt.dt.dayofweek        # 0=Mon\n",
    "df[\"admit_weekofyear\"] = dt.dt.isocalendar().week.astype(int)\n",
    "\n",
    "# hourly shift start\n",
    "df[\"shift_start\"] = dt.dt.floor(\"h\")\n",
    "\n",
    "print(\"\\nTime feature example:\")\n",
    "print(df[[\"hospital_admit_time_parsed\",\n",
    "          \"shift_start\", \"admit_hour\",\n",
    "          \"admit_dow\", \"admit_month\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacc5562-3a51-43ab-bbe2-7f7f3dc6e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 5. Age in years + pediatric / geriatric flags\n",
    "# ---------------------------------------------------------\n",
    "def normalize_age(row):\n",
    "    val = row[\"patient_age_value\"]\n",
    "    try:\n",
    "        return float(str(val).strip())\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "df[\"age_years\"] = df.apply(normalize_age, axis=1)\n",
    "df[\"is_pediatric\"] = (df[\"age_years\"] < 18).astype(\"Int8\")\n",
    "df[\"is_geriatric\"] = (df[\"age_years\"] >= 65).astype(\"Int8\")\n",
    "\n",
    "# scene / case-mix numeric features\n",
    "df[\"num_patients_at_scene\"] = pd.to_numeric(\n",
    "    df[\"num_patients_at_scene\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# any non‑missing value in possible_injury_flag -> 1\n",
    "df[\"possible_injury_bin\"] = df[\"possible_injury_flag\"].apply(\n",
    "    lambda v: 0 if pd.isna(v) else 1\n",
    ")\n",
    "\n",
    "# optional simple trauma_high flag from trauma_score_or_severity\n",
    "df[\"trauma_score\"] = pd.to_numeric(df[\"trauma_score_or_severity\"],\n",
    "                                   errors=\"coerce\")\n",
    "if df[\"trauma_score\"].notna().sum() > 0:\n",
    "    thr = df[\"trauma_score\"].quantile(0.75)\n",
    "    df[\"trauma_high\"] = (df[\"trauma_score\"] >= thr).astype(\"Int8\")\n",
    "else:\n",
    "    df[\"trauma_high\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "311a5157-4352-4e7b-a2ea-be2682f4702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hourly aggregation head:\n",
      "          shift_start  call_volume  avg_num_patients  max_num_patients  \\\n",
      "0 2023-12-31 21:00:00            2         2707005.0           2707005   \n",
      "1 2024-01-01 00:00:00            1         2707005.0           2707005   \n",
      "2 2024-01-01 01:00:00            1         7701003.0           7701003   \n",
      "3 2024-01-01 02:00:00            5         2707005.0           2707005   \n",
      "4 2024-01-01 03:00:00            4         3955504.5           7701003   \n",
      "\n",
      "   possible_injury_prop  trauma_high_prop  pediatric_prop  geriatric_prop  \\\n",
      "0                   1.0               1.0             0.0             1.0   \n",
      "1                   1.0               1.0             0.0             0.0   \n",
      "2                   1.0               1.0             1.0             0.0   \n",
      "3                   1.0               0.8             0.2             0.4   \n",
      "4                   1.0              0.25             0.0            0.25   \n",
      "\n",
      "   service_mode_nunique  hour  dow  month  \n",
      "0                     1    21    6     12  \n",
      "1                     1     0    0      1  \n",
      "2                     1     1    0      1  \n",
      "3                     2     2    0      1  \n",
      "4                     1     3    0      1  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 6. Aggregate to hourly shift level\n",
    "# ---------------------------------------------------------\n",
    "agg = df.groupby(\"shift_start\").agg(\n",
    "    call_volume=(\"incident_id\", \"count\"),\n",
    "    avg_num_patients=(\"num_patients_at_scene\", \"mean\"),\n",
    "    max_num_patients=(\"num_patients_at_scene\", \"max\"),\n",
    "    possible_injury_prop=(\"possible_injury_bin\", \"mean\"),\n",
    "    trauma_high_prop=(\"trauma_high\", \"mean\"),\n",
    "    pediatric_prop=(\"is_pediatric\", \"mean\"),\n",
    "    geriatric_prop=(\"is_geriatric\", \"mean\"),\n",
    "    service_mode_nunique=(\"service_requested_type\", \"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "agg = agg.sort_values(\"shift_start\")\n",
    "agg[\"hour\"] = agg[\"shift_start\"].dt.hour\n",
    "agg[\"dow\"] = agg[\"shift_start\"].dt.dayofweek\n",
    "agg[\"month\"] = agg[\"shift_start\"].dt.month\n",
    "\n",
    "print(\"\\nHourly aggregation head:\")\n",
    "print(agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb12ed9-6b50-42f4-9ef1-c09e6cc5bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High‑strain threshold (top 25% calls/hour): 5.0\n",
      "high_strain\n",
      "0    30\n",
      "1    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 7. Define high‑strain target (top 25% call volume)\n",
    "# ---------------------------------------------------------\n",
    "quantile_thresh = agg[\"call_volume\"].quantile(0.75)\n",
    "agg[\"high_strain\"] = (agg[\"call_volume\"] >= quantile_thresh).astype(int)\n",
    "\n",
    "print(\"\\nHigh‑strain threshold (top 25% calls/hour):\", quantile_thresh)\n",
    "print(agg[\"high_strain\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d94057b-dd4e-4fd5-8062-f3ec5e29b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train hours: 28  Test hours: 13\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 8. Prepare features and time‑ordered train/test split\n",
    "# ---------------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"hour\", \"dow\", \"month\",\n",
    "    \"avg_num_patients\", \"max_num_patients\",\n",
    "    \"possible_injury_prop\", \"trauma_high_prop\",\n",
    "    \"pediatric_prop\", \"geriatric_prop\",\n",
    "    \"service_mode_nunique\",\n",
    "]\n",
    "\n",
    "agg[feature_cols] = agg[feature_cols].fillna(0)\n",
    "\n",
    "X = agg[feature_cols].values\n",
    "y_reg = agg[\"call_volume\"].values\n",
    "y_cls = agg[\"high_strain\"].values\n",
    "\n",
    "n = len(agg)\n",
    "split_idx = int(n * 0.7)  # 70% earlier hours for train\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_reg_train, y_reg_test = y_reg[:split_idx], y_reg[split_idx:]\n",
    "y_cls_train, y_cls_test = y_cls[:split_idx], y_cls[split_idx:]\n",
    "\n",
    "print(\"\\nTrain hours:\", X_train.shape[0], \" Test hours:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccd7d73-4894-4151-951f-9bee8b7b1b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Linear Regression (call volume) ===\n",
      "MAE: 1.3553833656215468\n",
      "R^2: -17.30540778189656\n",
      "\n",
      "=== Random Forest Regressor (call volume) ===\n",
      "MAE: 1.038076923076923\n",
      "R^2: -9.975412500000001\n",
      "\n",
      "=== Logistic Regression (high‑strain) ===\n",
      "ROC‑AUC: nan\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        13\n",
      "\n",
      "    accuracy                          1.000        13\n",
      "   macro avg      1.000     1.000     1.000        13\n",
      "weighted avg      1.000     1.000     1.000        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Classifier (high‑strain) ===\n",
      "ROC‑AUC: nan\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        13\n",
      "\n",
      "    accuracy                          1.000        13\n",
      "   macro avg      1.000     1.000     1.000        13\n",
      "weighted avg      1.000     1.000     1.000        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Application\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 9. Models: volume regression + high‑strain classification\n",
    "# ---------------------------------------------------------\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, r2_score,\n",
    "    roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "# Regression: hourly call volume\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_reg_train)\n",
    "y_reg_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Linear Regression (call volume) ===\")\n",
    "print(\"MAE:\", mean_absolute_error(y_reg_test, y_reg_pred_lin))\n",
    "print(\"R^2:\", r2_score(y_reg_test, y_reg_pred_lin))\n",
    "\n",
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_reg.fit(X_train, y_reg_train)\n",
    "y_reg_pred_rf = rf_reg.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Regressor (call volume) ===\")\n",
    "print(\"MAE:\", mean_absolute_error(y_reg_test, y_reg_pred_rf))\n",
    "print(\"R^2:\", r2_score(y_reg_test, y_reg_pred_rf))\n",
    "\n",
    "# Classification: high‑strain vs normal hour\n",
    "log_cls = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "log_cls.fit(X_train, y_cls_train)\n",
    "y_prob_log = log_cls.predict_proba(X_test)[:, 1]\n",
    "y_pred_log = (y_prob_log >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Logistic Regression (high‑strain) ===\")\n",
    "print(\"ROC‑AUC:\", roc_auc_score(y_cls_test, y_prob_log))\n",
    "print(classification_report(y_cls_test, y_pred_log, digits=3))\n",
    "\n",
    "rf_cls = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "rf_cls.fit(X_train, y_cls_train)\n",
    "y_prob_rf = rf_cls.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf = (y_prob_rf >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Random Forest Classifier (high‑strain) ===\")\n",
    "print(\"ROC‑AUC:\", roc_auc_score(y_cls_test, y_prob_rf))\n",
    "print(classification_report(y_cls_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3f787-3b7a-4f2a-9daf-5e06a0c61b98",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
